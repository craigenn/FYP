View(newtotal)
solution<-as.data.frame(table(unlist(newtotal)))
View(solution)
table(solution)
columns <- c('_index' , '_type', '_source.layers.frame.frame.time', '_source.layers.ip.ip.addr', '_source.layers.ip.ip.dst')
newtotal2 <- newtotal[, columns]
newtotal2 <- newtotal[, c('_index' , '_type', '_source.layers.frame.frame.time', '_source.layers.ip.ip.addr', '_source.layers.ip.ip.dst')]
View(newtotal)
columns <- c('X_index' , 'X_type', 'X_source.layers.frame.frame.time', 'X_source.layers.ip.ip.addr', 'X_source.layers.ip.ip.dst')
newtotal2 <- newtotal[, columns]
View(newtotal2)
table(newtotal2)
runApp()
shiny::runApp()
runApp()
h2o.init(nthreads = 4)
model <- h2o.loadModel("StackedEnsemble")
mydf <- read.csv("attfile.csv")
View(mydf)
View(mydf)
View(mydf)
packets_h20 <- as.h2o(mydf)
pred <- h2o.predict(model, packets_h20)
h2o.explain(pred)
h2o.explain(model, packets_h20)
h2o.explain(model, packets_h20)
View(mydf)
mydf <- read.csv("test.csv")
View(mydf)
mydf <- read.csv("testt.csv")
View(mydf)
View(mydf)
packets_h20 <- as.h2o(mydf)
model <- h2o.loadModel("StackedEnsemble")
pred <- h2o.predict(model, packets_h20)
h2o.explain(model, packets_h20)
runApp()
h2o.explain(model, packets_h20)
h2o.init(nthreads = 4)
model <- h2o.loadModel("StackedEnsemble")
mydf <- read.csv("testt.csv")
mydf <- read.csv("testt.csv")
packets_h20 <- as.h2o(mydf)
pred <- h2o.predict(model, packets_h20)
predoutput <- as.data.frame(pred)
View(predoutput)
View(predoutput)
total <- cbind(mydf, predoutput)
View(total)
columns <- c('X_index' , 'X_type', 'X_source.layers.frame.frame.time', 'X_source.layers.ip.ip.addr', 'X_source.layers.ip.ip.dst')
#library(data.table)
newtotal <- total[total$predict == "1", ]
newtotal2 <- newtotal[, columns]
table(newtotal2)
View(total)
runApp()
install.packages("gridExtra")
d <- head(newtotal2[,1:5])
grid.table(d)
library(grid)
grid.table(d)
install.packages("grid")
install.packages("grid")
d <- head(newtotal2[,1:5])
View(d)
library(h2o)
h2o.init(nthreads = 4)
model <- h2o.loadModel("StackedEnsemble")
model <- h2o.loadModel("StackedEnsemble")
mydf <- read.csv("packetlist.csv")
packets_h20 <- as.h2o(mydf)
pred <- h2o.predict(model, packets_h20)
h2o.explain(model, packets_h20)
pred <- h2o.predict(model, packets_h20)
setwd("~/BrunelOnedrive/OneDrive - Brunel University London/Brunelwork/fyp/FYP")
library(h2o)
#dataset
mydf <- read.csv("packetlistclass.csv")
mydf$Class <- as.factor(df$Class)
#convert input into h20frame
packets_h20 <- as.h2o(mydf)
packets_h20$Class <- as.factor(packets_h20$Class)
#take a look at the h20 frame
h2o.describe(packets_h20)
#Split data into train and test
y <- "Class"
df_splits <- h2o.splitFrame(data = packets_h20, ratios = 0.50, seed = 1)
train <- df_splits[[1]]
test <- df_splits[[2]]
x <- setdiff(names(train), y)
train[, y] <- as.factor(train[, y])
test[, y] <- as.factor(test[, y])
#number of cv folds
nfolds <-5
# Train & Cross-validate a GBM
my_gbm <- h2o.gbm(x = x,
y = y,
training_frame = train,
distribution = "bernoulli",
ntrees = 10,
max_depth = 3,
min_rows = 2,
learn_rate = 0.2,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
# Train & Cross-validate a RF
my_rf <- h2o.randomForest(x = x,
y = y,
training_frame = train,
ntrees = 50,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
# Train a stacked ensemble using the GBM and RF above
ensemble <- h2o.stackedEnsemble(x = x,
y = y,
training_frame = train,
base_models = list(my_gbm, my_rf))
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble, newdata = test)
# Compare to base learner performance on the test set
perf_gbm_test <- h2o.performance(my_gbm, newdata = test)
perf_rf_test <- h2o.performance(my_rf, newdata = test)
baselearner_best_auc_test <- max(h2o.auc(perf_gbm_test), h2o.auc(perf_rf_test))
ensemble_auc_test <- h2o.auc(perf)
print(sprintf("Best Base-learner Test AUC:  %s", baselearner_best_auc_test))
print(sprintf("Ensemble Test AUC:  %s", ensemble_auc_test))
# Generate predictions on a test set (if neccessary)
pred <- h2o.predict(ensemble, newdata = test)
h2o.explain(ensemble, test)
h2o.explain(my_gbm, test)
#NN in h2o
h2o_nn <- h2o.deeplearning(x = 2:154,
y = 1,
training_frame = packets_h20,
nfolds = 5
)
h2o.explain(h2o_nn, test)
mydf2 <- read.csv("testt.csv")
packets_h202 <- as.h2o(mydf2)
#take a look at the h20 frame
h2o.describe(packets_h202)
test2 <- packets_h202
h2o.explain(h2o_nn, test2)
h2o.explain(h2o_nn, test)
model <- h2o.loadModel("StackedEnsemble")
mydf <- read.csv("packetlist.csv")
packets_h20 <- as.h2o(mydf)
pred <- h2o.predict(model, packets_h20)
#h2o.explain(model, packets_h20)
predoutput <- as.data.frame(pred)
total <- cbind(mydf, predoutput)
columns <- c('X_index' , 'X_type', 'X_source.layers.frame.frame.time', 'X_source.layers.ip.ip.addr', 'X_source.layers.ip.ip.dst')
#library(data.table)
newtotal <- total[total$predict == "1", ]
newtotal2 <- newtotal[, columns]
table(newtotal2)
shiny::runApp()
h2o.init(nthreads = 4)
model <- h2o.loadModel("StackedEnsemble")
mydf <- read.csv("testtclass.csv")
packets_h20 <- as.h2o(mydf)
h2o.explain(model, packets_h20)
h2o.confusionMatrix(model, packets_h20)
setwd("~/BrunelOnedrive/OneDrive - Brunel University London/Brunelwork/fyp/FYP")
library(h2o)
#dataset
mydf <- read.csv("packetlistclass.csv")
#start h20 cluster instance
h2o.init(nthreads = 4)
#convert input into h20frame
packets_h20 <- as.h2o(mydf)
packets_h20$Class <- as.factor(packets_h20$Class)
#Split data into train and test
y <- "Class"
df_splits <- h2o.splitFrame(data = packets_h20, ratios = 0.70, seed = 1)
train <- df_splits[[1]]
test <- df_splits[[2]]
x <- setdiff(names(train), y)
train[, y] <- as.factor(train[, y])
test[, y] <- as.factor(test[, y])
#number of cv folds
nfolds <-5
# Train & Cross-validate a GBM
my_gbm <- h2o.gbm(x = x,
y = y,
training_frame = train,
distribution = "bernoulli",
ntrees = 10,
max_depth = 3,
min_rows = 2,
learn_rate = 0.2,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
# Train & Cross-validate a RF
my_rf <- h2o.randomForest(x = x,
y = y,
training_frame = train,
ntrees = 50,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
#NN in h2o
h2o_nn <- h2o.deeplearning(x = 2:154,
y = 1,
training_frame = packets_h20,
nfolds = 5
)
View(h2o_nn)
#NN in h2o
my_nn <- h2o.deeplearning(x = x,
y = y,
training_frame = train,
nfolds = 5
)
#NN in h2o
my_nn <- h2o.deeplearning(x = x,
y = y,
training_frame = train,
nfolds = 5,
keep_cross_validation_predictions = TRUE,
)
my_svm <- h2o.psvm(x=x,
y=y,
training_frame = train,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
)
my_svm <- h2o.psvm(x=x,
y=y,
training_frame = train,
)
my_nb <- h2o.naiveBayes(x=x,
y=y,
training_frame = train,
nfolds = nfolds,
seed = 1
)
h2o.performance(h2o_nn)
h2o.performance(my_nn)
h2o.performance(my_nb)
h2o.performance(my_svm)
h2o.performance(my_rf)
#rf, nn , gbm
# Train a stacked ensemble using the GBM and RF above
ensemble <- h2o.stackedEnsemble(x = x,
y = y,
training_frame = train,
base_models = list(my_gbm, my_rf, my_nn))
#NN in h2o
my_nn <- h2o.deeplearning(x = x,
y = y,
training_frame = train,
nfolds = 5,
keep_cross_validation_predictions = TRUE,
seed=1
)
h2o.performance(my_nn)
#rf, nn , gbm
# Train a stacked ensemble using the GBM and RF above
ensemble <- h2o.stackedEnsemble(x = x,
y = y,
training_frame = train,
base_models = list(my_gbm, my_rf, my_nn))
mydf2 <- read.csv("testt.csv")
#remove class id column
packets <- mydf[,-1]
packets_h202 <- as.h2o(mydf2)
test2 <- packets_h202
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble, newdata = test2)
mydf2 <- read.csv("testtclass.csv")
packets_h202 <- as.h2o(mydf2)
packets_h20$Class <- as.factor(packets_h202$Class)
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble, newdata = test2)
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble, newdata = test)
View(perf)
h2o.explain(ensemble, test)
h2o.saveModel(ensemble2, path = getwd(), force = TRUE)
#rf, nn , gbm
# Train a stacked ensemble using the GBM and RF above
ensemble2 <- h2o.stackedEnsemble(x = x,
y = y,
training_frame = train,
base_models = list(my_gbm, my_rf, my_nn))
h2o.saveModel(ensemble2, path = getwd(), force = TRUE)
model <- h2o.loadModel("StackedEnsemble2")
mydf <- read.csv("moreatt.csv")
packets_h20 <- as.h2o(mydf)
h2o.confusionMatrix(model, packets_h20)
pred <- h2o.predict(model, packets_h20)
total <- cbind(mydf, predoutput)
columns <- c('X_index' , 'X_type', 'X_source.layers.frame.frame.time', 'X_source.layers.ip.ip.addr', 'X_source.layers.ip.ip.dst')
#library(data.table)
newtotal <- total[total$predict == "1", ]
total <- cbind(mydf, predoutput)
predoutput <- as.data.frame(pred)
total <- cbind(mydf, predoutput)
columns <- c('X_index' , 'X_type', 'X_source.layers.frame.frame.time', 'X_source.layers.ip.ip.addr', 'X_source.layers.ip.ip.dst')
#library(data.table)
newtotal <- total[total$predict == "1", ]
newtotal2 <- newtotal[, columns]
View(newtotal2)
h2o.explain(model, packets_h20)
model2 <- h2o.loadModel("StackedEnsemble")
pred2 <- h2o.predict(model2, packets_h20)
predoutput2 <- as.data.frame(pred2)
total2 <- cbind(mydf, predoutput2)
newtotal3 <- total2[total2$predict == "1", ]
newtotal4 <- newtotal3[, columns]
View(newtotal2)
View(newtotal4)
View(newtotal4)
h2o.confusionMatrix(model, packets_h20)
View(pred)
View(predoutput)
View(predoutput2)
View(newtotal)
View(newtotal3)
runApp()
mydf <- read.csv("testtclass.csv")
packets_h20 <- as.h2o(mydf)
pred2 <- h2o.predict(model2, packets_h20)
h2o.explain(model2, packets_h20)
h2o.init(nthreads = 4)
packets_h20 <- as.h2o(mydf)
pred2 <- h2o.predict(model2, packets_h20)
model2 <- h2o.loadModel("StackedEnsemble")
pred2 <- h2o.predict(model2, packets_h20)
h2o.confusionMatrix(model2, packets_h20)
shiny::runApp()
my_km <- h2o.kmeans(training_frame = train,
validation_frame = y,
k = 2,
seed = 1,
)
setwd("~/BrunelOnedrive/OneDrive - Brunel University London/Brunelwork/fyp/FYP")
library(h2o)
#dataset
mydf <- read.csv("packetlistclass.csv")
mydf2 <- read.csv("testtclass.csv")
#start h20 cluster instance
h2o.init(nthreads = 4)
#convert input into h20frame
packets_h20 <- as.h2o(mydf)
packets_h202 <- as.h2o(mydf2)
packets_h20$Class <- as.factor(packets_h20$Class)
#Split data into train and test
y <- "Class"
df_splits <- h2o.splitFrame(data = packets_h20, ratios = 0.70, seed = 1)
train <- df_splits[[1]]
test <- df_splits[[2]]
test2 <- packets_h202
x <- setdiff(names(train), y)
train[, y] <- as.factor(train[, y])
test[, y] <- as.factor(test[, y])
#number of cv folds
nfolds <-5
# Train & Cross-validate a GBM
my_gbm <- h2o.gbm(x = x,
y = y,
training_frame = train,
distribution = "bernoulli",
ntrees = 10,
max_depth = 3,
min_rows = 2,
learn_rate = 0.2,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
# Train & Cross-validate a RF
my_rf <- h2o.randomForest(x = x,
y = y,
training_frame = train,
ntrees = 50,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
#NN in h2o
my_nn <- h2o.deeplearning(x = x,
y = y,
training_frame = train,
nfolds = 5,
keep_cross_validation_predictions = TRUE,
seed=1
)
my_km <- h2o.kmeans(training_frame = train,
validation_frame = y,
k = 2,
seed = 1,
)
my_km <- h2o.kmeans(training_frame = train,
validation_frame = test,
k = 2,
seed = 1,
)
h2o.performance(my_km)
h2o.confusionMatrix(my_km)
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("~/BrunelOnedrive/OneDrive - Brunel University London/Brunelwork/fyp/FYP")
setwd("~/BrunelOnedrive/OneDrive - Brunel University London/Brunelwork/fyp/FYP")
library(h2o)
#dataset
mydf <- read.csv("packetlistclassprocessed.csv")
#start h20 cluster instance
h2o.init(nthreads = 4)
#convert input into h20frame
packets_h20 <- as.h2o(mydf)
packets_h20$Class <- as.factor(packets_h20$Class)
#Split data into train and test
y <- "Class"
df_splits <- h2o.splitFrame(data = packets_h20, ratios = 0.70, seed = 1)
train <- df_splits[[1]]
test <- df_splits[[2]]
x <- setdiff(names(train), y)
#mydf$Class <- as.factor(df$Class)
mydf2 <- read.csv("testtclass.csv")
packets_h202 <- as.h2o(mydf2)
packets_h202$Class <- as.factor(packets_h202$Class)
train[, y] <- as.factor(train[, y])
test[, y] <- as.factor(test[, y])
#number of cv folds
nfolds <-5
# Train & Cross-validate a GBM
my_gbm <- h2o.gbm(x = x,
y = y,
training_frame = train,
distribution = "bernoulli",
ntrees = 10,
max_depth = 3,
min_rows = 2,
learn_rate = 0.2,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
# Train & Cross-validate a RF
my_rf <- h2o.randomForest(x = x,
y = y,
training_frame = train,
ntrees = 50,
nfolds = nfolds,
keep_cross_validation_predictions = TRUE,
seed = 1)
#NN in h2o
my_nn <- h2o.deeplearning(x = x,
y = y,
training_frame = train,
nfolds = 5,
keep_cross_validation_predictions = TRUE,
seed=1
)
my_km <- h2o.kmeans(training_frame = train,
validation_frame = test,
k = 2,
seed = 1,
)
my_svm <- h2o.psvm(x=x,
y=y,
training_frame = train,
)
my_nb <- h2o.naiveBayes(x=x,
y=y,
training_frame = train,
nfolds = nfolds,
seed = 1
)
h2o.confusionMatrix(my_rf)
h2o.confusionMatrix(my_svm)
h2o.confusionMatrix(my_nn)
h2o.confusionMatrix(my_gbm)
#rf, nn , gbm
# Train a stacked ensemble using the GBM and RF above
ensemble2 <- h2o.stackedEnsemble(x = x,
y = y,
training_frame = train,
base_models = list(my_gbm, my_rf, my_nn))
h2o.confusionMatrix(ensemble2)
h2o.explain(ensemble, test)
h2o.explain(ensemble2, test)
h2o.confusionMatrix(ensemble2)
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble, newdata = test2)
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble2, newdata = test2)
View(packets_h202)
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble2, newdata = packets_h202)
packets_h202$Class <- as.factor(packets_h202$Class)
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble2, newdata = packets_h202)
# Eval ensemble performance on a test set
perf <- h2o.performance(ensemble2, newdata = test)
ensemble_auc_test <- h2o.auc(perf)
print(sprintf("Ensemble Test AUC:  %s", ensemble_auc_test))
runApp()
shiny::runApp()
shiny::runApp()
